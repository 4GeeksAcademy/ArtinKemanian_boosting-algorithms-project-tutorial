{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np # linear algebra\n",
                "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
                "\n",
                "import seaborn as sns # Visualization\n",
                "import matplotlib.pyplot as plt # Visualization\n",
                "from colorama import Fore\n",
                "\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
                "import math\n",
                "\n",
                "import warnings # Supress warnings \n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "np.random.seed(7)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "import numpy as np # linear algebra\n",
                "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
                "\n",
                "# Input data files are available in the read-only \"../input/\" directory\n",
                "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
                "\n",
                "import os\n",
                "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
                "    for filename in filenames:\n",
                "        # print(os.path.join(dirname, filename))\n",
                "        pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "ename": "FileNotFoundError",
                    "evalue": "[Errno 2] No such file or directory: '../input/acea-water-prediction/Aquifer_Petrignano.csv'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../input/acea-water-prediction/Aquifer_Petrignano.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
                        "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
                        "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
                        "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
                        "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/acea-water-prediction/Aquifer_Petrignano.csv'"
                    ]
                }
            ],
            "source": [
                "df = pd.read_csv(\"../input/acea-water-prediction/Aquifer_Petrignano.csv\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'df' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Remove old rows\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[df\u001b[38;5;241m.\u001b[39mRainfall_Bastia_Umbra\u001b[38;5;241m.\u001b[39mnotna()]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Remove not usefull columns\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepth_to_Groundwater_P24\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTemperature_Petrignano\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
                    ]
                }
            ],
            "source": [
                "# Remove old rows\n",
                "df = df[df.Rainfall_Bastia_Umbra.notna()].reset_index(drop=True)\n",
                "# Remove not usefull columns\n",
                "df = df.drop(['Depth_to_Groundwater_P24', 'Temperature_Petrignano'], axis=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'df' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrainfall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth_to_groundwater\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrainage_volume\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mriver_hydrometry\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m targets \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth_to_groundwater\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m features \u001b[38;5;241m=\u001b[39m [feature \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m feature \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m targets]\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
                    ]
                }
            ],
            "source": [
                "df.columns = ['date', 'rainfall', 'depth_to_groundwater', 'temperature', 'drainage_volume', 'river_hydrometry']\n",
                "\n",
                "targets = ['depth_to_groundwater']\n",
                "features = [feature for feature in df.columns if feature not in targets]\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from datetime import datetime, date \n",
                "\n",
                "df['date'] = pd.to_datetime(df['date'], format = '%d/%m/%Y')\n",
                "df.head().style.set_properties(subset=['date'], **{'background-color': 'dodgerblue'})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# To compelte the data, as naive method, we will use ffill\n",
                "f, ax = plt.subplots(nrows=5, ncols=1, figsize=(15, 25))\n",
                "\n",
                "for i, column in enumerate(df.drop('date', axis=1).columns):\n",
                "    sns.lineplot(x=df['date'], y=df[column].fillna(method='ffill'), ax=ax[i], color='dodgerblue')\n",
                "    ax[i].set_title('Feature: {}'.format(column), fontsize=14)\n",
                "    ax[i].set_ylabel(ylabel=column, fontsize=14)\n",
                "                      \n",
                "    ax[i].set_xlim([date(2009, 1, 1), date(2020, 6, 30)])  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df.sort_values(by='date')\n",
                "\n",
                "# Check time intervals\n",
                "df['delta'] = df['date'] - df['date'].shift(1)\n",
                "\n",
                "df[['date', 'delta']].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['delta'].sum(), df['delta'].count()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df.drop('delta', axis=1)\n",
                "df.isna().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "f, ax = plt.subplots(nrows=2, ncols=1, figsize=(15, 15))\n",
                "\n",
                "old_hydrometry = df['river_hydrometry'].copy()\n",
                "df['river_hydrometry'] = df['river_hydrometry'].replace(0, np.nan)\n",
                "\n",
                "sns.lineplot(x=df['date'], y=old_hydrometry, ax=ax[0], color='darkorange', label='original')\n",
                "sns.lineplot(x=df['date'], y=df['river_hydrometry'].fillna(np.inf), ax=ax[0], color='dodgerblue', label='modified')\n",
                "ax[0].set_title('Feature: Hydrometry', fontsize=14)\n",
                "ax[0].set_ylabel(ylabel='Hydrometry', fontsize=14)\n",
                "ax[0].set_xlim([date(2009, 1, 1), date(2020, 6, 30)])\n",
                "\n",
                "old_drainage = df['drainage_volume'].copy()\n",
                "df['drainage_volume'] = df['drainage_volume'].replace(0, np.nan)\n",
                "\n",
                "sns.lineplot(x=df['date'], y=old_drainage, ax=ax[1], color='darkorange', label='original')\n",
                "sns.lineplot(x=df['date'], y=df['drainage_volume'].fillna(np.inf), ax=ax[1], color='dodgerblue', label='modified')\n",
                "ax[1].set_title('Feature: Drainage', fontsize=14)\n",
                "ax[1].set_ylabel(ylabel='Drainage', fontsize=14)\n",
                "ax[1].set_xlim([date(2009, 1, 1), date(2020, 6, 30)])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(16,5))\n",
                "\n",
                "sns.heatmap(df.T.isna(), cmap='Blues')\n",
                "ax.set_title('Missing Values', fontsize=16)\n",
                "\n",
                "for tick in ax.yaxis.get_major_ticks():\n",
                "    tick.label.set_fontsize(14)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "f, ax = plt.subplots(nrows=4, ncols=1, figsize=(15, 12))\n",
                "\n",
                "sns.lineplot(x=df['date'], y=df['drainage_volume'].fillna(0), ax=ax[0], color='darkorange', label = 'modified')\n",
                "sns.lineplot(x=df['date'], y=df['drainage_volume'].fillna(np.inf), ax=ax[0], color='dodgerblue', label = 'original')\n",
                "ax[0].set_title('Fill NaN with 0', fontsize=14)\n",
                "ax[0].set_ylabel(ylabel='Volume C10 Petrignano', fontsize=14)\n",
                "\n",
                "mean_drainage = df['drainage_volume'].mean()\n",
                "sns.lineplot(x=df['date'], y=df['drainage_volume'].fillna(mean_drainage), ax=ax[1], color='darkorange', label = 'modified')\n",
                "sns.lineplot(x=df['date'], y=df['drainage_volume'].fillna(np.inf), ax=ax[1], color='dodgerblue', label = 'original')\n",
                "ax[1].set_title(f'Fill NaN with Mean Value ({mean_drainage:.0f})', fontsize=14)\n",
                "ax[1].set_ylabel(ylabel='Volume C10 Petrignano', fontsize=14)\n",
                "\n",
                "sns.lineplot(x=df['date'], y=df['drainage_volume'].ffill(), ax=ax[2], color='darkorange', label = 'modified')\n",
                "sns.lineplot(x=df['date'], y=df['drainage_volume'].fillna(np.inf), ax=ax[2], color='dodgerblue', label = 'original')\n",
                "ax[2].set_title(f'FFill', fontsize=14)\n",
                "ax[2].set_ylabel(ylabel='Volume C10 Petrignano', fontsize=14)\n",
                "\n",
                "sns.lineplot(x=df['date'], y=df['drainage_volume'].interpolate(), ax=ax[3], color='darkorange', label = 'modified')\n",
                "sns.lineplot(x=df['date'], y=df['drainage_volume'].fillna(np.inf), ax=ax[3], color='dodgerblue', label = 'original')\n",
                "ax[3].set_title(f'Interpolate', fontsize=14)\n",
                "ax[3].set_ylabel(ylabel='Volume C10 Petrignano', fontsize=14)\n",
                "\n",
                "for i in range(4):\n",
                "    ax[i].set_xlim([date(2019, 5, 1), date(2019, 10, 1)])\n",
                "    \n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['drainage_volume'] = df['drainage_volume'].interpolate()\n",
                "df['river_hydrometry'] = df['river_hydrometry'].interpolate()\n",
                "df['depth_to_groundwater'] = df['depth_to_groundwater'].interpolate()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(ncols=2, nrows=3, sharex=True, figsize=(16,12))\n",
                "\n",
                "sns.lineplot(df['date'], df['drainage_volume'], color='dodgerblue', ax=ax[0, 0])\n",
                "ax[0, 0].set_title('Drainage Volume', fontsize=14)\n",
                "\n",
                "resampled_df = df[['date','drainage_volume']].resample('7D', on='date').sum().reset_index(drop=False)\n",
                "sns.lineplot(resampled_df['date'], resampled_df['drainage_volume'], color='dodgerblue', ax=ax[1, 0])\n",
                "ax[1, 0].set_title('Weekly Drainage Volume', fontsize=14)\n",
                "\n",
                "resampled_df = df[['date','drainage_volume']].resample('M', on='date').sum().reset_index(drop=False)\n",
                "sns.lineplot(resampled_df['date'], resampled_df['drainage_volume'], color='dodgerblue', ax=ax[2, 0])\n",
                "ax[2, 0].set_title('Monthly Drainage Volume', fontsize=14)\n",
                "\n",
                "for i in range(3):\n",
                "    ax[i, 0].set_xlim([date(2009, 1, 1), date(2020, 6, 30)])\n",
                "\n",
                "sns.lineplot(df['date'], df['temperature'], color='dodgerblue', ax=ax[0, 1])\n",
                "ax[0, 1].set_title('Daily Temperature (Acc.)', fontsize=14)\n",
                "\n",
                "resampled_df = df[['date','temperature']].resample('7D', on='date').mean().reset_index(drop=False)\n",
                "sns.lineplot(resampled_df['date'], resampled_df['temperature'], color='dodgerblue', ax=ax[1, 1])\n",
                "ax[1, 1].set_title('Weekly Temperature (Acc.)', fontsize=14)\n",
                "\n",
                "resampled_df = df[['date','temperature']].resample('M', on='date').mean().reset_index(drop=False)\n",
                "sns.lineplot(resampled_df['date'], resampled_df['temperature'], color='dodgerblue', ax=ax[2, 1])\n",
                "ax[2, 1].set_title('Monthly Temperature (Acc.)', fontsize=14)\n",
                "\n",
                "for i in range(3):\n",
                "    ax[i, 1].set_xlim([date(2009, 1, 1), date(2020, 6, 30)])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# As we can see, downsample to weekly could smooth the data and hgelp with analysis\n",
                "downsample = df[['date',\n",
                "                 'depth_to_groundwater', \n",
                "                 'temperature',\n",
                "                 'drainage_volume', \n",
                "                 'river_hydrometry',\n",
                "                 'rainfall'\n",
                "                ]].resample('7D', on='date').mean().reset_index(drop=False)\n",
                "\n",
                "df = downsample.copy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# A year has 52 weeks (52 weeks * 7 days per week) aporx.\n",
                "rolling_window = 52\n",
                "f, ax = plt.subplots(nrows=2, ncols=1, figsize=(15, 12))\n",
                "\n",
                "sns.lineplot(x=df['date'], y=df['drainage_volume'], ax=ax[0], color='dodgerblue')\n",
                "sns.lineplot(x=df['date'], y=df['drainage_volume'].rolling(rolling_window).mean(), ax=ax[0], color='black', label='rolling mean')\n",
                "sns.lineplot(x=df['date'], y=df['drainage_volume'].rolling(rolling_window).std(), ax=ax[0], color='orange', label='rolling std')\n",
                "ax[0].set_title('Depth to Groundwater: Non-stationary \\nnon-constant mean & non-constant variance', fontsize=14)\n",
                "ax[0].set_ylabel(ylabel='Drainage Volume', fontsize=14)\n",
                "ax[0].set_xlim([date(2009, 1, 1), date(2020, 6, 30)])\n",
                "\n",
                "sns.lineplot(x=df['date'], y=df['temperature'], ax=ax[1], color='dodgerblue')\n",
                "sns.lineplot(x=df['date'], y=df['temperature'].rolling(rolling_window).mean(), ax=ax[1], color='black', label='rolling mean')\n",
                "sns.lineplot(x=df['date'], y=df['temperature'].rolling(rolling_window).std(), ax=ax[1], color='orange', label='rolling std')\n",
                "ax[1].set_title('Temperature: Non-stationary \\nvariance is time-dependent (seasonality)', fontsize=14)\n",
                "ax[1].set_ylabel(ylabel='Temperature', fontsize=14)\n",
                "ax[1].set_xlim([date(2009, 1, 1), date(2020, 6, 30)])\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from statsmodels.tsa.stattools import adfuller\n",
                "\n",
                "result = adfuller(df['depth_to_groundwater'].values)\n",
                "result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "f, ax = plt.subplots(nrows=3, ncols=2, figsize=(15, 9))\n",
                "\n",
                "def visualize_adfuller_results(series, title, ax):\n",
                "    result = adfuller(series)\n",
                "    significance_level = 0.05\n",
                "    adf_stat = result[0]\n",
                "    p_val = result[1]\n",
                "    crit_val_1 = result[4]['1%']\n",
                "    crit_val_5 = result[4]['5%']\n",
                "    crit_val_10 = result[4]['10%']\n",
                "\n",
                "    if (p_val < significance_level) & ((adf_stat < crit_val_1)):\n",
                "        linecolor = 'forestgreen' \n",
                "    elif (p_val < significance_level) & (adf_stat < crit_val_5):\n",
                "        linecolor = 'orange'\n",
                "    elif (p_val < significance_level) & (adf_stat < crit_val_10):\n",
                "        linecolor = 'red'\n",
                "    else:\n",
                "        linecolor = 'purple'\n",
                "    sns.lineplot(x=df['date'], y=series, ax=ax, color=linecolor)\n",
                "    ax.set_title(f'ADF Statistic {adf_stat:0.3f}, p-value: {p_val:0.3f}\\nCritical Values 1%: {crit_val_1:0.3f}, 5%: {crit_val_5:0.3f}, 10%: {crit_val_10:0.3f}', fontsize=14)\n",
                "    ax.set_ylabel(ylabel=title, fontsize=14)\n",
                "\n",
                "visualize_adfuller_results(df['rainfall'].values, 'Rainfall', ax[0, 0])\n",
                "visualize_adfuller_results(df['temperature'].values, 'Temperature', ax[1, 0])\n",
                "visualize_adfuller_results(df['river_hydrometry'].values, 'River_Hydrometry', ax[0, 1])\n",
                "visualize_adfuller_results(df['drainage_volume'].values, 'Drainage_Volume', ax[1, 1])\n",
                "visualize_adfuller_results(df['depth_to_groundwater'].values, 'Depth_to_Groundwater', ax[2, 0])\n",
                "\n",
                "f.delaxes(ax[2, 1])\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Log Transform of absolute values\n",
                "# (Log transoform of negative values will return NaN)\n",
                "df['depth_to_groundwater_log'] = np.log(abs(df['depth_to_groundwater']))\n",
                "\n",
                "f, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 6))\n",
                "visualize_adfuller_results(df['depth_to_groundwater_log'], 'Transformed \\n Depth to Groundwater', ax[0])\n",
                "\n",
                "sns.distplot(df['depth_to_groundwater_log'], ax=ax[1])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ts_diff = np.diff(df['depth_to_groundwater'])\n",
                "df['depth_to_groundwater_diff_1'] = np.append([0], ts_diff)\n",
                "\n",
                "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 6))\n",
                "visualize_adfuller_results(df['depth_to_groundwater_diff_1'], 'Differenced (1. Order) \\n Depth to Groundwater', ax)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['year'] = pd.DatetimeIndex(df['date']).year\n",
                "df['month'] = pd.DatetimeIndex(df['date']).month\n",
                "df['day'] = pd.DatetimeIndex(df['date']).day\n",
                "df['day_of_year'] = pd.DatetimeIndex(df['date']).dayofyear\n",
                "df['week_of_year'] = pd.DatetimeIndex(df['date']).weekofyear\n",
                "df['quarter'] = pd.DatetimeIndex(df['date']).quarter\n",
                "df['season'] = df['month'] % 12 // 3 + 1\n",
                "\n",
                "df[['date', 'year', 'month', 'day', 'day_of_year', 'week_of_year', 'quarter', 'season']].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 3))\n",
                "\n",
                "sns.lineplot(x=df['date'], y=df['month'], color='dodgerblue')\n",
                "ax.set_xlim([date(2009, 1, 1), date(2020, 6, 30)])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "month_in_year = 12\n",
                "df['month_sin'] = np.sin(2*np.pi*df['month']/month_in_year)\n",
                "df['month_cos'] = np.cos(2*np.pi*df['month']/month_in_year)\n",
                "\n",
                "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
                "\n",
                "sns.scatterplot(x=df.month_sin, y=df.month_cos, color='dodgerblue')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from statsmodels.tsa.seasonal import seasonal_decompose\n",
                "\n",
                "core_columns =  [\n",
                "    'rainfall', 'temperature', 'drainage_volume', \n",
                "    'river_hydrometry', 'depth_to_groundwater'\n",
                "]\n",
                "\n",
                "for column in core_columns:\n",
                "    decomp = seasonal_decompose(df[column], period=52, model='additive', extrapolate_trend='freq')\n",
                "    df[f\"{column}_trend\"] = decomp.trend\n",
                "    df[f\"{column}_seasonal\"] = decomp.seasonal"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(ncols=2, nrows=4, sharex=True, figsize=(16,8))\n",
                "\n",
                "for i, column in enumerate(['temperature', 'depth_to_groundwater']):\n",
                "    \n",
                "    res = seasonal_decompose(df[column], freq=52, model='additive', extrapolate_trend='freq')\n",
                "\n",
                "    ax[0,i].set_title('Decomposition of {}'.format(column), fontsize=16)\n",
                "    res.observed.plot(ax=ax[0,i], legend=False, color='dodgerblue')\n",
                "    ax[0,i].set_ylabel('Observed', fontsize=14)\n",
                "\n",
                "    res.trend.plot(ax=ax[1,i], legend=False, color='dodgerblue')\n",
                "    ax[1,i].set_ylabel('Trend', fontsize=14)\n",
                "\n",
                "    res.seasonal.plot(ax=ax[2,i], legend=False, color='dodgerblue')\n",
                "    ax[2,i].set_ylabel('Seasonal', fontsize=14)\n",
                "    \n",
                "    res.resid.plot(ax=ax[3,i], legend=False, color='dodgerblue')\n",
                "    ax[3,i].set_ylabel('Residual', fontsize=14)\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "weeks_in_month = 4\n",
                "\n",
                "for column in core_columns:\n",
                "    df[f'{column}_seasonal_shift_b_2m'] = df[f'{column}_seasonal'].shift(-2 * weeks_in_month)\n",
                "    df[f'{column}_seasonal_shift_b_1m'] = df[f'{column}_seasonal'].shift(-1 * weeks_in_month)\n",
                "    df[f'{column}_seasonal_shift_1m'] = df[f'{column}_seasonal'].shift(1 * weeks_in_month)\n",
                "    df[f'{column}_seasonal_shift_2m'] = df[f'{column}_seasonal'].shift(2 * weeks_in_month)\n",
                "    df[f'{column}_seasonal_shift_3m'] = df[f'{column}_seasonal'].shift(3 * weeks_in_month)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "f, ax = plt.subplots(nrows=5, ncols=1, figsize=(15, 12))\n",
                "f.suptitle('Seasonal Components of Features', fontsize=16)\n",
                "\n",
                "for i, column in enumerate(core_columns):\n",
                "    sns.lineplot(x=df['date'], y=df[column + '_seasonal'], ax=ax[i], color='dodgerblue', label='P25')\n",
                "    ax[i].set_ylabel(ylabel=column, fontsize=14)\n",
                "    ax[i].set_xlim([date(2017, 9, 30), date(2020, 6, 30)])\n",
                "    \n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "f, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 8))\n",
                "\n",
                "corrmat = df[core_columns].corr()\n",
                "\n",
                "sns.heatmap(corrmat, annot=True, vmin=-1, vmax=1, cmap='coolwarm_r', ax=ax[0])\n",
                "ax[0].set_title('Correlation Matrix of Core Features', fontsize=16)\n",
                "\n",
                "shifted_cols = [\n",
                "    'depth_to_groundwater_seasonal',         \n",
                "    'temperature_seasonal_shift_b_2m',\n",
                "    'drainage_volume_seasonal_shift_2m', \n",
                "    'river_hydrometry_seasonal_shift_3m'\n",
                "]\n",
                "corrmat = df[shifted_cols].corr()\n",
                "\n",
                "sns.heatmap(corrmat, annot=True, vmin=-1, vmax=1, cmap='coolwarm_r', ax=ax[1])\n",
                "ax[1].set_title('Correlation Matrix of Lagged Features', fontsize=16)\n",
                "\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pandas.plotting import autocorrelation_plot\n",
                "\n",
                "autocorrelation_plot(df['depth_to_groundwater_diff_1'])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from statsmodels.graphics.tsaplots import plot_acf\n",
                "from statsmodels.graphics.tsaplots import plot_pacf\n",
                "\n",
                "f, ax = plt.subplots(nrows=2, ncols=1, figsize=(16, 8))\n",
                "\n",
                "plot_acf(df['depth_to_groundwater_diff_1'], lags=100, ax=ax[0])\n",
                "plot_pacf(df['depth_to_groundwater_diff_1'], lags=100, ax=ax[1])\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import TimeSeriesSplit\n",
                "\n",
                "N_SPLITS = 3\n",
                "\n",
                "X = df['date']\n",
                "y = df['depth_to_groundwater']\n",
                "\n",
                "folds = TimeSeriesSplit(n_splits=N_SPLITS)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "f, ax = plt.subplots(nrows=N_SPLITS, ncols=2, figsize=(16, 9))\n",
                "\n",
                "for i, (train_index, valid_index) in enumerate(folds.split(X)):\n",
                "    X_train, X_valid = X[train_index], X[valid_index]\n",
                "    y_train, y_valid = y[train_index], y[valid_index]\n",
                "\n",
                "    sns.lineplot(\n",
                "        x=X_train, \n",
                "        y=y_train, \n",
                "        ax=ax[i,0], \n",
                "        color='dodgerblue', \n",
                "        label='train'\n",
                "    )\n",
                "    sns.lineplot(\n",
                "        x=X_train[len(X_train) - len(X_valid):(len(X_train) - len(X_valid) + len(X_valid))], \n",
                "        y=y_train[len(X_train) - len(X_valid):(len(X_train) - len(X_valid) + len(X_valid))], \n",
                "        ax=ax[i,1], \n",
                "        color='dodgerblue', \n",
                "        label='train'\n",
                "    )\n",
                "\n",
                "    for j in range(2):\n",
                "        sns.lineplot(x= X_valid, y= y_valid, ax=ax[i, j], color='darkorange', label='validation')\n",
                "    ax[i, 0].set_title(f\"Rolling Window with Adjusting Training Size (Split {i+1})\", fontsize=16)\n",
                "    ax[i, 1].set_title(f\"Rolling Window with Constant Training Size (Split {i+1})\", fontsize=16)\n",
                "\n",
                "for i in range(N_SPLITS):\n",
                "    ax[i, 0].set_xlim([date(2009, 1, 1), date(2020, 6, 30)])\n",
                "    ax[i, 1].set_xlim([date(2009, 1, 1), date(2020, 6, 30)])\n",
                "    \n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_size = int(0.85 * len(df))\n",
                "test_size = len(df) - train_size\n",
                "\n",
                "univariate_df = df[['date', 'depth_to_groundwater']].copy()\n",
                "univariate_df.columns = ['ds', 'y']\n",
                "\n",
                "train = univariate_df.iloc[:train_size, :]\n",
                "\n",
                "x_train, y_train = pd.DataFrame(univariate_df.iloc[:train_size, 0]), pd.DataFrame(univariate_df.iloc[:train_size, 1])\n",
                "x_valid, y_valid = pd.DataFrame(univariate_df.iloc[train_size:, 0]), pd.DataFrame(univariate_df.iloc[train_size:, 1])\n",
                "\n",
                "print(len(train), len(x_valid))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
                "import math\n",
                "\n",
                "from fbprophet import Prophet\n",
                "\n",
                "\n",
                "# Train the model\n",
                "model = Prophet()\n",
                "model.fit(train)\n",
                "\n",
                "# x_valid = model.make_future_dataframe(periods=test_size, freq='w')\n",
                "\n",
                "# Predict on valid set\n",
                "y_pred = model.predict(x_valid)\n",
                "\n",
                "# Calcuate metrics\n",
                "score_mae = mean_absolute_error(y_valid, y_pred.tail(test_size)['yhat'])\n",
                "score_rmse = math.sqrt(mean_squared_error(y_valid, y_pred.tail(test_size)['yhat']))\n",
                "\n",
                "print(Fore.GREEN + 'RMSE: {}'.format(score_rmse))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot the forecast\n",
                "f, ax = plt.subplots(1)\n",
                "f.set_figheight(6)\n",
                "f.set_figwidth(15)\n",
                "\n",
                "model.plot(y_pred, ax=ax)\n",
                "sns.lineplot(x=x_valid['ds'], y=y_valid['y'], ax=ax, color='orange', label='Ground truth') #navajowhite\n",
                "\n",
                "ax.set_title(f'Prediction \\n MAE: {score_mae:.2f}, RMSE: {score_rmse:.2f}', fontsize=14)\n",
                "ax.set_xlabel(xlabel='Date', fontsize=14)\n",
                "ax.set_ylabel(ylabel='Depth to Groundwater', fontsize=14)\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from statsmodels.tsa.arima_model import ARIMA\n",
                "\n",
                "# Fit model\n",
                "model = ARIMA(y_train, order=(1,1,1))\n",
                "model_fit = model.fit()\n",
                "\n",
                "# Prediction with ARIMA\n",
                "y_pred, se, conf = model_fit.forecast(90)\n",
                "\n",
                "# Calcuate metrics\n",
                "score_mae = mean_absolute_error(y_valid, y_pred)\n",
                "score_rmse = math.sqrt(mean_squared_error(y_valid, y_pred))\n",
                "\n",
                "print(Fore.GREEN + 'RMSE: {}'.format(score_rmse))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "f, ax = plt.subplots(1)\n",
                "f.set_figheight(6)\n",
                "f.set_figwidth(15)\n",
                "\n",
                "model_fit.plot_predict(1, 599, ax=ax)\n",
                "sns.lineplot(x=x_valid.index, y=y_valid['y'], ax=ax, color='orange', label='Ground truth') #navajowhite\n",
                "\n",
                "ax.set_title(f'Prediction \\n MAE: {score_mae:.2f}, RMSE: {score_rmse:.2f}', fontsize=14)\n",
                "ax.set_xlabel(xlabel='Date', fontsize=14)\n",
                "ax.set_ylabel(ylabel='Depth to Groundwater', fontsize=14)\n",
                "\n",
                "ax.set_ylim(-35, -18)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "f, ax = plt.subplots(1)\n",
                "f.set_figheight(4)\n",
                "f.set_figwidth(15)\n",
                "\n",
                "sns.lineplot(x=x_valid.index, y=y_pred, ax=ax, color='blue', label='predicted') #navajowhite\n",
                "sns.lineplot(x=x_valid.index, y=y_valid['y'], ax=ax, color='orange', label='Ground truth') #navajowhite\n",
                "\n",
                "ax.set_xlabel(xlabel='Date', fontsize=14)\n",
                "ax.set_ylabel(ylabel='Depth to Groundwater', fontsize=14)\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from statsmodels.tsa.arima_model import ARIMA\n",
                "import pmdarima as pm\n",
                "\n",
                "model = pm.auto_arima(y_train, start_p=1, start_q=1,\n",
                "                      test='adf',       # use adftest to find optimal 'd'\n",
                "                      max_p=3, max_q=3, # maximum p and q\n",
                "                      m=1,              # frequency of series\n",
                "                      d=None,           # let model determine 'd'\n",
                "                      seasonal=False,   # No Seasonality\n",
                "                      start_P=0, \n",
                "                      D=0, \n",
                "                      trace=True,\n",
                "                      error_action='ignore',  \n",
                "                      suppress_warnings=True, \n",
                "                      stepwise=True)\n",
                "\n",
                "print(model.summary())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.plot_diagnostics(figsize=(16,8))\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.preprocessing import MinMaxScaler\n",
                "\n",
                "data = univariate_df.filter(['y'])\n",
                "#Convert the dataframe to a numpy array\n",
                "dataset = data.values\n",
                "\n",
                "scaler = MinMaxScaler(feature_range=(-1, 0))\n",
                "scaled_data = scaler.fit_transform(dataset)\n",
                "\n",
                "scaled_data[:10]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Defines the rolling window\n",
                "look_back = 52\n",
                "# Split into train and test sets\n",
                "train, test = scaled_data[:train_size-look_back,:], scaled_data[train_size-look_back:,:]\n",
                "\n",
                "def create_dataset(dataset, look_back=1):\n",
                "    X, Y = [], []\n",
                "    for i in range(look_back, len(dataset)):\n",
                "        a = dataset[i-look_back:i, 0]\n",
                "        X.append(a)\n",
                "        Y.append(dataset[i, 0])\n",
                "    return np.array(X), np.array(Y)\n",
                "\n",
                "x_train, y_train = create_dataset(train, look_back)\n",
                "x_test, y_test = create_dataset(test, look_back)\n",
                "\n",
                "# reshape input to be [samples, time steps, features]\n",
                "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
                "x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
                "\n",
                "print(len(x_train), len(x_test))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from keras.models import Sequential\n",
                "from keras.layers import Dense, LSTM\n",
                "\n",
                "#Build the LSTM model\n",
                "model = Sequential()\n",
                "model.add(LSTM(128, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
                "model.add(LSTM(64, return_sequences=False))\n",
                "model.add(Dense(25))\n",
                "model.add(Dense(1))\n",
                "\n",
                "# Compile the model\n",
                "model.compile(optimizer='adam', loss='mean_squared_error')\n",
                "\n",
                "#Train the model\n",
                "model.fit(x_train, y_train, batch_size=1, epochs=5, validation_data=(x_test, y_test))\n",
                "\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Lets predict with the model\n",
                "train_predict = model.predict(x_train)\n",
                "test_predict = model.predict(x_test)\n",
                "\n",
                "# invert predictions\n",
                "train_predict = scaler.inverse_transform(train_predict)\n",
                "y_train = scaler.inverse_transform([y_train])\n",
                "\n",
                "test_predict = scaler.inverse_transform(test_predict)\n",
                "y_test = scaler.inverse_transform([y_test])\n",
                "\n",
                "# Get the root mean squared error (RMSE) and MAE\n",
                "score_rmse = np.sqrt(mean_squared_error(y_test[0], test_predict[:,0]))\n",
                "score_mae = mean_absolute_error(y_test[0], test_predict[:,0])\n",
                "print(Fore.GREEN + 'RMSE: {}'.format(score_rmse))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x_train_ticks = univariate_df.head(train_size)['ds']\n",
                "y_train = univariate_df.head(train_size)['y']\n",
                "x_test_ticks = univariate_df.tail(test_size)['ds']\n",
                "\n",
                "# Plot the forecast\n",
                "f, ax = plt.subplots(1)\n",
                "f.set_figheight(6)\n",
                "f.set_figwidth(15)\n",
                "\n",
                "sns.lineplot(x=x_train_ticks, y=y_train, ax=ax, label='Train Set') #navajowhite\n",
                "sns.lineplot(x=x_test_ticks, y=test_predict[:,0], ax=ax, color='green', label='Prediction') #navajowhite\n",
                "sns.lineplot(x=x_test_ticks, y=y_test[0], ax=ax, color='orange', label='Ground truth') #navajowhite\n",
                "\n",
                "ax.set_title(f'Prediction \\n MAE: {score_mae:.2f}, RMSE: {score_rmse:.2f}', fontsize=14)\n",
                "ax.set_xlabel(xlabel='Date', fontsize=14)\n",
                "ax.set_ylabel(ylabel='Depth to Groundwater', fontsize=14)\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "feature_columns = [\n",
                "    'rainfall',\n",
                "    'temperature',\n",
                "    'drainage_volume',\n",
                "    'river_hydrometry',\n",
                "]\n",
                "target_column = ['depth_to_groundwater']\n",
                "\n",
                "train_size = int(0.85 * len(df))\n",
                "\n",
                "multivariate_df = df[['date'] + target_column + feature_columns].copy()\n",
                "multivariate_df.columns = ['ds', 'y'] + feature_columns\n",
                "\n",
                "train = multivariate_df.iloc[:train_size, :]\n",
                "x_train, y_train = pd.DataFrame(multivariate_df.iloc[:train_size, [0,2,3,4,5]]), pd.DataFrame(multivariate_df.iloc[:train_size, 1])\n",
                "x_valid, y_valid = pd.DataFrame(multivariate_df.iloc[train_size:, [0,2,3,4,5]]), pd.DataFrame(multivariate_df.iloc[train_size:, 1])\n",
                "\n",
                "train.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from fbprophet import Prophet\n",
                "\n",
                "\n",
                "# Train the model\n",
                "model = Prophet()\n",
                "model.add_regressor('rainfall')\n",
                "model.add_regressor('temperature')\n",
                "model.add_regressor('drainage_volume')\n",
                "model.add_regressor('river_hydrometry')\n",
                "\n",
                "# Fit the model with train set\n",
                "model.fit(train)\n",
                "\n",
                "# Predict on valid set\n",
                "y_pred = model.predict(x_valid)\n",
                "\n",
                "# Calcuate metrics\n",
                "score_mae = mean_absolute_error(y_valid, y_pred['yhat'])\n",
                "score_rmse = math.sqrt(mean_squared_error(y_valid, y_pred['yhat']))\n",
                "\n",
                "print(Fore.GREEN + 'RMSE: {}'.format(score_rmse))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot the forecast\n",
                "f, ax = plt.subplots(1)\n",
                "f.set_figheight(6)\n",
                "f.set_figwidth(15)\n",
                "\n",
                "model.plot(y_pred, ax=ax)\n",
                "sns.lineplot(x=x_valid['ds'], y=y_valid['y'], ax=ax, color='orange', label='Ground truth') #navajowhite\n",
                "\n",
                "ax.set_title(f'Prediction \\n MAE: {score_mae:.2f}, RMSE: {score_rmse:.2f}', fontsize=14)\n",
                "ax.set_xlabel(xlabel='Date', fontsize=14)\n",
                "ax.set_ylabel(ylabel='Depth to Groundwater', fontsize=14)\n",
                "\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
